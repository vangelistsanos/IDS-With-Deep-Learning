{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgddns0-0mQU"
      },
      "source": [
        "# ΠΤΥΧΙΑΚΗ ΕΡΓΑΣΙΑ\n",
        "\n",
        "### Μέρος ΙΙ (TabNet)\n",
        "\n",
        "## Τσάνος Ευάγγελος\n",
        "\n",
        "# Θέμα : \"Ανίχνευση διαδικτυακών Επιθέσεων με χρήση νευρωνικών δικτύων\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3j9C4HqWd-2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Περιεχόμενα\n",
        "--\n",
        "\n",
        "1.Functions imports and parameters\n",
        "\n",
        "2.Φόρτωση Δεδομένων για τον TabNet\n",
        "\n",
        "3.Preprocessing\n",
        "\n",
        "4.TabNet\n",
        "\n",
        "5.Αξιολόγηση TabNet\n",
        "\n",
        "6.Κατέβασμα αρχείων μοντέλου για χρήση απο API\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITAYAMkr1OIB"
      },
      "source": [
        "# 1.Functions imports and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcLtSErj2Vdf",
        "outputId": "e2709796-89df-4559-adbf-18e568275670"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gCgcFcg_zOT"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------\n",
        "# Βασικά\n",
        "# ----------------------------------------------------------\n",
        "import os\n",
        "import shutil\n",
        "import pickle\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Οπτικοποίηση\n",
        "# ----------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Google Drive\n",
        "# ----------------------------------------------------------\n",
        "from google.colab import drive, files\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Προεπεξεργασία & Sampling\n",
        "# ----------------------------------------------------------\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αξιολόγηση\n",
        "# ----------------------------------------------------------\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# PyTorch & TabNet\n",
        "# ----------------------------------------------------------\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yh06WRXAwwl",
        "outputId": "730ceef7-a437-4c46-fb39-8b6140143b35"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w8ilmnbAUD8"
      },
      "outputs": [],
      "source": [
        "# To path που έχουμε κατεβάσει τα αρχεία στο GoogleDrive μας\n",
        "base_path = '/content/drive/My Drive/UNSW-NB15/'\n",
        "\n",
        "# Επιλογή του μεγέθους του dataset που θα δουλέψουμε για όλους τους αλγόριθμους\n",
        "# Σε περίπτωση που θέλουμε να τρέξουμε tuning καλό είναι να μην πάμε με\n",
        "# ολόκληρο το dataset. Ένα 30% θα εκτελεστεί σε ικανοποιητικούς χρόνους.\n",
        "# Για απευθειας εκτέλεση με τις παρακάτω τιμές σε περιβάλλον google colab\n",
        "# και επιλεγμένη hi-ram και T4 cpu θα χρειαστούν περίπου 60 λεπτά.\n",
        "USE_TUNER = False\n",
        "FRACTION = 1.0 #100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuKVv_Ym1Fa2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function που χρησιμοποιείται για την φόρτωση των αρχείων\n",
        "def load_unsw_data_from_google_drive(data_path: str, fraction: float = 1.0, encoding: str = 'ISO-8859-1', random_state: int = 42):\n",
        "    train_file = os.path.join(data_path, 'UNSW_NB15_training-set.csv')\n",
        "    test_file = os.path.join(data_path, 'UNSW_NB15_testing-set.csv')\n",
        "    try:\n",
        "        df_train = pd.read_csv(train_file, encoding=encoding)\n",
        "        df_test = pd.read_csv(test_file, encoding=encoding)\n",
        "\n",
        "        if 0 < fraction < 1.0:\n",
        "            df_train = df_train.sample(frac=fraction, random_state=random_state).reset_index(drop=True)\n",
        "            df_test = df_test.sample(frac=fraction, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "        print(\"Training set loaded. Shape:\", df_train.shape)\n",
        "        print(\"Testing set loaded. Shape:\", df_test.shape)\n",
        "        return df_train, df_test\n",
        "    except FileNotFoundError:\n",
        "        print(\"Τα αρχεία training ή testing δεν βρέθηκαν. Έλεγξε τη διαδρομή:\", data_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Σφάλμα κατά τη φόρτωση: {e}\")\n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLQok5NBXPQ"
      },
      "source": [
        "# 2. Φόρτωση Δεδομένων για τον TabNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIW6apxLBo72",
        "outputId": "49403960-7276-47e7-c53f-72bfe530fd77"
      },
      "outputs": [],
      "source": [
        "# Φόρτωση αρχείων για τα μοντέλα μας\n",
        "# εδώ παίζει ρόλο η παράμετρος FRACTION\n",
        "try:\n",
        "    df_train, df_test = load_unsw_data_from_google_drive(base_path, fraction=FRACTION)\n",
        "except FileNotFoundError:\n",
        "    print(\"Τα αρχεία δεν βρέθηκαν. Παρακαλώ ελέγξτε τη διαδρομή.\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά τη φόρτωση των αρχείων: {e}\")\n",
        "\n",
        "\n",
        "if df_train is not None and df_test is not None:\n",
        "    print(df_train.head())\n",
        "    df_train.info()\n",
        "else:\n",
        "    print(\"Δεν φορτώθηκαν δεδομένα.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydOzJjBiH3-E"
      },
      "source": [
        "# 3. Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WowWortjnNp",
        "outputId": "2bec7923-aa37-4f19-d89d-b3675cd71be5"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------\n",
        "# Καθαρισμός και επιλογή χαρακτηριστικών\n",
        "# ----------------------------------------------------------\n",
        "features = df_train.columns.tolist()\n",
        "features = [col for col in features if col not in ['ï»¿id', 'label', 'attack_cat']]\n",
        "\n",
        "X_train_raw = df_train[features].copy()\n",
        "X_test_raw  = df_test[features].copy()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αντικατάσταση σπάνιων κατηγοριών\n",
        "# ----------------------------------------------------------\n",
        "threshold = 100\n",
        "for col in X_train_raw.select_dtypes(include='object').columns:\n",
        "    value_counts = X_train_raw[col].value_counts()\n",
        "    rare_values = value_counts[value_counts < threshold].index\n",
        "    X_train_raw[col] = X_train_raw[col].replace(rare_values, 'rare')\n",
        "    X_test_raw[col]  = X_test_raw[col].replace(rare_values, 'rare')\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αντιγραφή για χρήση με TabNet\n",
        "# ----------------------------------------------------------\n",
        "X_train_tabnet = X_train_raw.copy()\n",
        "X_test_tabnet  = X_test_raw.copy()\n",
        "\n",
        "categorical_cols_tabnet = X_train_tabnet.select_dtypes(include='object').columns.tolist()\n",
        "cat_idxs = []\n",
        "cat_dims = []\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Label Encoding κατηγορικών χαρακτηριστικών και αποθήκευση\n",
        "# encoders\n",
        "# ----------------------------------------------------------\n",
        "for col in categorical_cols_tabnet:\n",
        "    le = LabelEncoder()\n",
        "    all_values = pd.concat([X_train_tabnet[col], X_test_tabnet[col]], axis=0).astype(str)\n",
        "    le.fit(all_values)\n",
        "    X_train_tabnet[col] = le.transform(X_train_tabnet[col].astype(str))\n",
        "    X_test_tabnet[col]  = le.transform(X_test_tabnet[col].astype(str))\n",
        "    cat_idxs.append(X_train_tabnet.columns.get_loc(col))\n",
        "    cat_dims.append(len(le.classes_))\n",
        "\n",
        "    os.makedirs(\"artifacts\", exist_ok=True)\n",
        "    joblib.dump(le, f\"artifacts/{col}_encoder.pkl\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Label Encoding για τον στόχο (attack_cat)\n",
        "# ----------------------------------------------------------\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(df_train['attack_cat'])\n",
        "y_test_encoded  = label_encoder.transform(df_test['attack_cat'])\n",
        "joblib.dump(label_encoder, \"artifacts/target_encoder.pkl\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Train/Validation split\n",
        "# ----------------------------------------------------------\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train_tabnet.values,\n",
        "    y_train_encoded,\n",
        "    test_size=0.2,\n",
        "    stratify=y_train_encoded,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Υπολογισμός class weights και sample weights\n",
        "# ----------------------------------------------------------\n",
        "classes = np.unique(y_train_split)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_split)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "sample_weights_tabnet = np.array([class_weight_dict[y] for y in y_train_split])\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αποθήκευση metadata και artifacts\n",
        "# ----------------------------------------------------------\n",
        "joblib.dump(categorical_cols_tabnet, \"artifacts/categorical_columns.pkl\")\n",
        "joblib.dump(X_train_tabnet.columns.tolist(), \"artifacts/feature_columns.pkl\")\n",
        "joblib.dump(cat_idxs, \"artifacts/cat_idxs.pkl\")\n",
        "joblib.dump(cat_dims, \"artifacts/cat_dims.pkl\")\n",
        "joblib.dump(class_weight_dict, \"artifacts/class_weight_dict.pkl\")\n",
        "joblib.dump(sample_weights_tabnet, \"artifacts/sample_weights_tabnet.npy\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Εμφάνιση ελέγχου\n",
        "# ----------------------------------------------------------\n",
        "print(\"TabNet preprocessing ολοκληρώθηκε.\")\n",
        "print(\"Κατηγορικά:\", categorical_cols_tabnet)\n",
        "print(\"cat_idxs:\", cat_idxs)\n",
        "print(\"cat_dims:\", cat_dims)\n",
        "print(\"class_weights:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: '{label}' ---> weight: {class_weight_dict[i]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ncDhPhS2gF"
      },
      "source": [
        "#4.TabNet (Training + Hyperparameter Tuning)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Vvv1I6ZrSZ",
        "outputId": "33ddca0a-a0c9-44b9-cfc1-740b5c10044c"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------\n",
        "# TabNet Training / Hyperparameter Tuning\n",
        "# ----------------------------------------\n",
        "best_model = None\n",
        "best_params = None\n",
        "best_acc = 0\n",
        "\n",
        "if USE_TUNER:\n",
        "    param_grid = [\n",
        "        {\"n_d\": 16, \"n_a\": 16, \"lr\": 0.01, \"n_steps\": 5, \"gamma\": 1.0},\n",
        "        {\"n_d\": 32, \"n_a\": 32, \"lr\": 0.01, \"n_steps\": 5, \"gamma\": 1.0},\n",
        "        {\"n_d\": 64, \"n_a\": 64, \"lr\": 0.01, \"n_steps\": 3, \"gamma\": 0.5},\n",
        "        {\"n_d\": 128, \"n_a\": 128, \"lr\": 0.01, \"n_steps\": 3, \"gamma\": 0.5},\n",
        "        {\"n_d\": 32, \"n_a\": 32, \"lr\": 0.02, \"n_steps\": 6, \"gamma\": 1.3},\n",
        "        {\"n_d\": 64, \"n_a\": 64, \"lr\": 0.001, \"n_steps\": 7, \"gamma\": 1.5},\n",
        "        {\"n_d\": 32, \"n_a\": 16, \"lr\": 0.005, \"n_steps\": 8, \"gamma\": 1.7},\n",
        "    ]\n",
        "\n",
        "    for i, params in enumerate(param_grid):\n",
        "        print(f\"\\nTrial {i+1} με παραμέτρους: {params}\")\n",
        "\n",
        "        clf = TabNetClassifier(\n",
        "            cat_idxs=cat_idxs,\n",
        "            cat_dims=cat_dims,\n",
        "            cat_emb_dim=8,\n",
        "            n_d=params[\"n_d\"],\n",
        "            n_a=params[\"n_a\"],\n",
        "            n_steps=params[\"n_steps\"],\n",
        "            gamma=params[\"gamma\"],\n",
        "            lambda_sparse=0.0001,\n",
        "            optimizer_fn=torch.optim.Adam,\n",
        "            optimizer_params=dict(lr=params[\"lr\"]),\n",
        "            mask_type='sparsemax',\n",
        "            verbose=1,\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        clf.fit(\n",
        "            X_train=X_train_split,\n",
        "            y_train=y_train_split,\n",
        "            eval_set=[(X_train_split, y_train_split), (X_val_split, y_val_split)],\n",
        "            eval_name=['train','val'],\n",
        "            eval_metric=['accuracy','logloss'],\n",
        "            max_epochs=50, #για το tuning αφήνω λίγα\n",
        "            patience=5,\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128,\n",
        "            num_workers=0,\n",
        "            drop_last=False,\n",
        "            weights=sample_weights_tabnet\n",
        "        )\n",
        "\n",
        "        y_pred_val = clf.predict(X_val_split)\n",
        "        acc = accuracy_score(y_val_split, y_pred_val)\n",
        "        print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_model = clf\n",
        "            best_params = params\n",
        "\n",
        "        history = clf.history\n",
        "else:\n",
        "    print(\"\\nSkip tuning - χρήση προκαθορισμένων υπερπαραμέτρων.\")\n",
        "    best_params =  {\"n_d\": 64, \"n_a\": 64, \"lr\": 0.001, \"n_steps\": 7, \"gamma\": 1.5}\n",
        "    #{'n_d': 128, 'n_a': 128, 'lr': 0.01, 'n_steps': 3, 'gamma': 0.5}\n",
        "     #{\"n_d\": 64, \"n_a\": 64, \"lr\": 0.001, \"n_steps\": 7, \"gamma\": 1.5}\n",
        "\n",
        "    best_model = TabNetClassifier(\n",
        "        cat_idxs=cat_idxs,\n",
        "        cat_dims=cat_dims,\n",
        "        cat_emb_dim=8,\n",
        "        n_d=best_params[\"n_d\"],\n",
        "        n_a=best_params[\"n_a\"],\n",
        "        n_steps=best_params[\"n_steps\"],\n",
        "        gamma=best_params[\"gamma\"],\n",
        "        lambda_sparse=0.0001,\n",
        "        optimizer_fn=torch.optim.Adam,\n",
        "        optimizer_params=dict(lr=best_params[\"lr\"]),\n",
        "        mask_type='entmax',\n",
        "        verbose=1,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    best_model.fit(\n",
        "        X_train=X_train_split,\n",
        "        y_train=y_train_split,\n",
        "        eval_set=[(X_train_split, y_train_split), (X_val_split, y_val_split)],\n",
        "        eval_name=['train','val'],\n",
        "        eval_metric=['accuracy','logloss'],\n",
        "        max_epochs=400,\n",
        "        patience=20,\n",
        "        batch_size=1024,\n",
        "        virtual_batch_size=128,\n",
        "        num_workers=0,\n",
        "        drop_last=False,\n",
        "        weights=sample_weights_tabnet\n",
        "    )\n",
        "\n",
        "    best_acc = accuracy_score(y_val_split, best_model.predict(X_val_split))\n",
        "    history = best_model.history\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ye475nb9Mi"
      },
      "source": [
        "## 5.Αξιολόγηση TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qncjfgLW7C88",
        "outputId": "0101fce9-9945-461e-c18c-612e0407ffae"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------\n",
        "# Evaluation on Test Set\n",
        "# --------------------------------------------------------\n",
        "print(f\"\\nΚαλύτερη Validation Accuracy: {best_acc:.4f}\")\n",
        "print(\"Καλύτερες υπερπαραμέτρους:\", best_params)\n",
        "\n",
        "y_pred_test = best_model.predict(X_test_tabnet.values)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Confusion Matrix\n",
        "# --------------------------------------------------------\n",
        "cm = confusion_matrix(y_test_encoded, y_pred_test)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - TabNet (Best Trial on Test Set)\")\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Αποθήκευση καλύτερου μοντέλου\n",
        "# --------------------------------------------------------\n",
        "export_path = \"artifacts\"\n",
        "os.makedirs(export_path, exist_ok=True)\n",
        "best_model.save_model(os.path.join(export_path, \"tabnet_best_model\"))\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Διαγράμματα εκπαίδευσης (Loss/Accuracy)\n",
        "# --------------------------------------------------------\n",
        "plt.figure()\n",
        "plt.plot(history['loss'], label='Train Loss')\n",
        "plt.plot(history['val_logloss'], label='Validation Loss', linestyle='--')\n",
        "plt.title(\"Loss ανά Εποχή (TabNet)\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation Accuracy', linestyle='--')\n",
        "plt.title(\"Accuracy ανά Εποχή (TabNet)\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Classification Report\n",
        "# --------------------------------------------------------\n",
        "print(\"\\nClassification Report στο Test Set:\")\n",
        "print(classification_report(y_test_encoded, y_pred_test, target_names=label_encoder.classes_,digits=4))\n",
        "\n",
        "print(f\"\\nMacro F1 Score:      {f1_score(y_test_encoded, y_pred_test, average='macro'):.4f}\")\n",
        "print(f\"Weighted F1 Score:   {f1_score(y_test_encoded, y_pred_test, average='weighted'):.4f}\")\n",
        "print(f\"Micro F1 Score:      {f1_score(y_test_encoded, y_pred_test, average='micro'):.4f}\")\n",
        "print(f\"Macro Precision:     {precision_score(y_test_encoded, y_pred_test, average='macro'):.4f}\")\n",
        "print(f\"Macro Recall:        {recall_score(y_test_encoded, y_pred_test, average='macro'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am-lvrbzcAhA"
      },
      "source": [
        "## 6.Κατέβασμα αρχείων μοντέλου για χρήση απο API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eB4cKkGNkIV1",
        "outputId": "d01075ad-a9ac-40de-95b5-467c2607ae2a"
      },
      "outputs": [],
      "source": [
        "# Δημιουργία zip από τον φάκελο /content/artifacts\n",
        "shutil.make_archive(\"artifacts\", 'zip', \"/content/artifacts\")\n",
        "\n",
        "# katέβασμα τοπικά\n",
        "files.download(\"artifacts.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
