{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ΠΤΥΧΙΑΚΗ ΕΡΓΑΣΙΑ\n",
        "\n",
        "### Μέρος Ι (EDA + MLP + CNN)\n",
        "\n",
        "## Τσάνος Ευάγγελος\n",
        "\n",
        "# Θέμα : \"Ανίχνευση διαδικτυακών Επιθέσεων με χρήση νευρωνικών δικτύων\""
      ],
      "metadata": {
        "id": "xgddns0-0mQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Περιεχόμενα\n",
        "--\n",
        "1.Functions imports and parameters\n",
        "\n",
        "2.EDA\n",
        "\n",
        "- 2.1 Ελεγχος κατανομής κλάσεων και οπτικοποίηση\n",
        "\n",
        "- 2.2 Επιπλέον έλεγχοι για null τιμές / μοναδικές τιμές επιθέσεων / ισορροπίας μεταξύ normal και επιθέσεων / Αριθμιτικά στατιστικά χαρακτηριστικά\n",
        "\n",
        "- 2.3 Correlation matrix με hover functionality\n",
        "\n",
        "- 2.4 Εντοπισμός outliers\n",
        "\n",
        "- 2.5 Συσχέτιση features με target value (attack_cat)\n",
        "\n",
        "3.Φόρτωση Δεδομένων για τους αλγόριθμους\n",
        "\n",
        "4.Preprocessing (κοινό και για τα 2 μοντέλα)\n",
        "\n",
        "5.MLP\n",
        "\n",
        "6.Αξιολόγηση MLP\n",
        "\n",
        "7.CNN\n",
        "\n",
        "8.Αξιολόγηση CNN\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPjMpRYuVM22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Functions imports and parameters"
      ],
      "metadata": {
        "id": "ITAYAMkr1OIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "BlZlzcRV-hf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Basic\n",
        "# ----------------------------------------------------------\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Οπτικοποίηση\n",
        "# ----------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Google Drive\n",
        "# ----------------------------------------------------------\n",
        "from google.colab import drive\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Προεπεξεργασία\n",
        "# ----------------------------------------------------------\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αξιολόγηση\n",
        "# ----------------------------------------------------------\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# TensorFlow / Keras\n",
        "# ----------------------------------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv1D,\n",
        "    BatchNormalization,\n",
        "    GlobalMaxPooling1D,\n",
        "    Input,\n",
        "    Dense,\n",
        "    Dropout\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Keras Tuner\n",
        "# ----------------------------------------------------------\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "OGtDLEsV9nZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "-yh06WRXAwwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To path που έχουμε κατεβάσει τα αρχεία στο GoogleDrive μας\n",
        "base_path = '/content/drive/My Drive/UNSW-NB15/'\n",
        "\n",
        "# Επιλογή του μεγέθους του dataset που θα δουλέψουμε για όλους τους αλγόριθμους\n",
        "# Σε περίπτωση που θέλουμε να τρέξουμε tuning καλό είναι να μην πάμε με\n",
        "# ολόκληρο το dataset. Ένα 30% θα εκτελεστεί σε ικανοποιητικούς χρόνους.\n",
        "# Για CNN θα χρειαστεί σίγουρα GPU στο google colab\n",
        "USE_TUNER = False\n",
        "FRACTION = 1.0 #100%"
      ],
      "metadata": {
        "id": "6w8ilmnbAUD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function που χρησιμοποιείται για την φόρτωση των αρχείων\n",
        "def load_unsw_data_from_google_drive(data_path: str, fraction: float = 1.0, encoding: str = 'ISO-8859-1', random_state: int = 42):\n",
        "    train_file = os.path.join(data_path, 'UNSW_NB15_training-set.csv')\n",
        "    test_file = os.path.join(data_path, 'UNSW_NB15_testing-set.csv')\n",
        "    try:\n",
        "        df_train = pd.read_csv(train_file, encoding=encoding)\n",
        "        df_test = pd.read_csv(test_file, encoding=encoding)\n",
        "\n",
        "        if 0 < fraction < 1.0:\n",
        "            df_train = df_train.sample(frac=fraction, random_state=random_state).reset_index(drop=True)\n",
        "            df_test = df_test.sample(frac=fraction, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "        print(\"Training set loaded. Shape:\", df_train.shape)\n",
        "        print(\"Testing set loaded. Shape:\", df_test.shape)\n",
        "        return df_train, df_test\n",
        "    except FileNotFoundError:\n",
        "        print(\"Τα αρχεία training ή testing δεν βρέθηκαν. Έλεγξε τη διαδρομή:\", data_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Σφάλμα κατά τη φόρτωση: {e}\")\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "MuKVv_Ym1Fa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. EDA\n"
      ],
      "metadata": {
        "id": "hGJHxb-Q0Sxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvT9xR360MRm"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------\n",
        "# Φόρτωση αρχείων για EDA\n",
        "# ----------------------------------------------------------\n",
        "try:\n",
        "    df_train, df_test = load_unsw_data_from_google_drive(base_path, fraction=1.0) #στο EDA παίρνουμε πάντα όλο το dataset\n",
        "except FileNotFoundError:\n",
        "    print(\"Τα αρχεία training ή testing δεν βρέθηκαν δεν βρέθηκαν. Παρακαλώ ελέγξτε τη διαδρομή.\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά τη φόρτωση των αρχείων: {e}\")\n",
        "\n",
        "\n",
        "if df_train is not None and df_test is not None:\n",
        "    print(df_train.head())\n",
        "    df_train.info()\n",
        "else:\n",
        "    print(\"Δεν φορτώθηκαν δεδομένα.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Ελεγχος κατανομής κλάσεων και οπτικοποίηση"
      ],
      "metadata": {
        "id": "JxSqW9r60iav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Ανάλυση της κατανομής των κλάσεων στο Training Set (attack_cat)\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\nΚατανομή κλάσεων (attack_cat) στο Training Set:\")\n",
        "print(df_train['attack_cat'].value_counts())\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Οπτικοποίηση της κατανομής των κλάσεων\n",
        "# ----------------------------------------------------------\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.countplot(data=df_train, y='attack_cat', order=df_train['attack_cat'].value_counts().index, palette='viridis')\n",
        "plt.title('Κατανομή Κλάσεων Επίθεσης στο Training Set')\n",
        "plt.xlabel('Αριθμός Εγγραφών')\n",
        "plt.ylabel('Κατηγορία Επίθεσης')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Υπολογισμός ποσοστών για καλύτερη κατανόηση της ανισορροπίας\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\nΠοσοστά Κατανομής Κλάσεων (attack_cat) στο Training Set:\")\n",
        "print(df_train['attack_cat'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Επανάληψη για το Testing Set - για να δούμε την\n",
        "# ανισοκατανομή και στο τεστ σετ\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\nΚατανομή κλάσεων (attack_cat) στο Testing Set:\")\n",
        "print(df_test['attack_cat'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.countplot(data=df_test, y='attack_cat', order=df_test['attack_cat'].value_counts().index, palette='magma')\n",
        "plt.title('Κατανομή Κλάσεων Επίθεσης στο Testing Set')\n",
        "plt.xlabel('Αριθμός Εγγραφών')\n",
        "plt.ylabel('Κατηγορία Επίθεσης')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H4SAarmF0gTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Επιπλέον έλεγχοι για null τιμές / μοναδικές τιμές επιθέσεων / ισορροπίας μεταξύ normal και επιθέσεων / Αριθμιτικά στατιστικά χαρακτηριστικά"
      ],
      "metadata": {
        "id": "g4Vlf1Cv2HIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Έλεγχος για null τιμές:\n",
        "print(\"\\nΑριθμός μηδενικών τιμών ανά στήλη:\")\n",
        "print(df_train.isnull().sum())\n",
        "\n",
        "#Έλεγχος μοναδικών τιμών στην ετικέτα:\n",
        "print(\"Μοναδικές κατηγορίες επιθέσεων:\")\n",
        "print(df_train['attack_cat'].unique())\n",
        "\n",
        "#Έλεγχος για ισορροπία μεταξύ \"normal\" και επιθέσεων:\n",
        "print(df_train['label'].value_counts())  # 1=attack 0=normal\n",
        "\n",
        "#Έλεγχος για ισορροπία μεταξύ τύπων επιθέσεων\n",
        "print(df_train['attack_cat'].value_counts())  # 1=attack 0=normal\n",
        "\n",
        "#Αριθμητικά στατιστικά χαρακτηριστικά\n",
        "print(df_train.describe())"
      ],
      "metadata": {
        "id": "cI4gIYVM2CNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 2.3 Correlation matrix με hover functionality"
      ],
      "metadata": {
        "id": "R6tRW9-I2dx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Αντιγραφή και Label Encoding\n",
        "df_encoded = df_train.copy()\n",
        "le = LabelEncoder()\n",
        "df_encoded['attack_cat'] = le.fit_transform(df_encoded['attack_cat'])\n",
        "\n",
        "# Αφαίρεση του id\n",
        "if 'ï»¿id' in df_encoded.columns:\n",
        "    df_encoded.drop(columns=['ï»¿id'], inplace=True)\n",
        "\n",
        "# Επιλογή μόνο αριθμητικών\n",
        "numeric_df = df_encoded.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# Υπολογισμός του correlation matrix\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "# Δημιουργία interactive heatmap με Plotly\n",
        "fig = px.imshow(\n",
        "    correlation_matrix,\n",
        "    text_auto=\".2f\",\n",
        "    color_continuous_scale='RdBu_r',\n",
        "    title='Interactive Correlation Matrix'\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1000,\n",
        "    height=1000\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vNzap2lk2gh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4 Εντοπισμός outliers\n"
      ],
      "metadata": {
        "id": "QmS5VAwU227K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_outliers(df, z_thresh=3.0, iqr_multiplier=1.5):\n",
        "    # Εντοπισμός αριθμητικών χαρακτηριστικών\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    df_numeric = df[numeric_cols]\n",
        "\n",
        "    # Z-score\n",
        "    z_scores = np.abs(zscore(df_numeric))\n",
        "    z_outliers = (z_scores > z_thresh)\n",
        "    z_counts = z_outliers.sum(axis=0)\n",
        "\n",
        "    # IQR\n",
        "    Q1 = df_numeric.quantile(0.25)\n",
        "    Q3 = df_numeric.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    iqr_outliers = ((df_numeric < (Q1 - iqr_multiplier * IQR)) |\n",
        "                    (df_numeric > (Q3 + iqr_multiplier * IQR)))\n",
        "    iqr_counts = iqr_outliers.sum()\n",
        "\n",
        "    # Συγκεντρωτικός πίνακας\n",
        "    result = pd.DataFrame({\n",
        "        'Z_Outliers': z_counts,\n",
        "        'IQR_Outliers': iqr_counts,\n",
        "        'Total_Rows': len(df),\n",
        "        'Z_%': (z_counts / len(df)) * 100,\n",
        "        'IQR_%': (iqr_counts / len(df)) * 100\n",
        "    })\n",
        "\n",
        "    # κατηγοριοποίηση\n",
        "    def suggest_action(pct):\n",
        "        if pct > 10:\n",
        "            return 'Πιθανός log-transform ή clipping'\n",
        "        elif pct > 1:\n",
        "            return 'Μέτριοι outliers - επανεξέταση'\n",
        "        else:\n",
        "            return 'Δεν χρειάζεται ενέργεια'\n",
        "\n",
        "    result['Πρόταση'] = result['Z_%'].apply(suggest_action)\n",
        "\n",
        "    return result.sort_values('Z_%', ascending=False)\n",
        "\n",
        "\n",
        "outlier_report = detect_outliers(df_train)\n",
        "display(outlier_report)"
      ],
      "metadata": {
        "id": "aUqRfdE63AEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Συσχέτιση features με target value (attack_cat)"
      ],
      "metadata": {
        "id": "XEwUEf-R3IpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Αν υπάρχουν χαρακτηριστικά που επηρρεάζουν πολύ λίγο θα μπορούσαμε να μην τα\n",
        "# χρησιμοποιήσουμε στα μοντέλα μας. Έτσι θα μειώναμε και το dataset. Παρόλα\n",
        "# αυτά για το δικό μας παράδειγμα δεν θα κάνουμε κάποια στήλη exclude.\n",
        "X = numeric_df.drop(columns=['label'])\n",
        "y = df_encoded['attack_cat']\n",
        "\n",
        "mi = mutual_info_classif(X, y, discrete_features='auto')\n",
        "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "mi_scores.plot(kind='bar')\n",
        "plt.title('Mutual Information των Χαρακτηριστικών με το Target')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H_xBBcwz3JRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Φόρτωση Δεδομένων για τους αλγόριθμους"
      ],
      "metadata": {
        "id": "QbLQok5NBXPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Φόρτωση αρχείων για τα μοντέλα μας\n",
        "# εδώ παίζει ρόλο η παράμετρος FRACTION !!!\n",
        "# ----------------------------------------------------------\n",
        "try:\n",
        "    df_train, df_test = load_unsw_data_from_google_drive(base_path, fraction=FRACTION)\n",
        "except FileNotFoundError:\n",
        "    print(\"Τα αρχεία training-set.csv ή testing-set.csv δεν βρέθηκαν. Παρακαλώ ελέγξτε τη διαδρομή.\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά τη φόρτωση των αρχείων: {e}\")\n",
        "\n",
        "\n",
        "if df_train is not None and df_test is not None:\n",
        "    print(df_train.head())\n",
        "    df_train.info()\n",
        "else:\n",
        "    print(\"Δεν φορτώθηκαν δεδομένα.\")"
      ],
      "metadata": {
        "id": "uIW6apxLBo72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preprocessing (κοινό και για τα 2 μοντέλα)"
      ],
      "metadata": {
        "id": "ydOzJjBiH3-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Καθαρισμός δεδομένων & Επιλογή χαρακτηριστικών\n",
        "# ----------------------------------------------------------\n",
        "features_to_exclude = ['ï»¿id', 'label', 'attack_cat']\n",
        "selected_features = [col for col in df_train.columns if col not in features_to_exclude]\n",
        "\n",
        "X_train_raw = df_train[selected_features].copy()\n",
        "X_test_raw  = df_test[selected_features].copy()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Εντοπισμός & Αντικατάσταση σπάνιων κατηγοριών\n",
        "# ----------------------------------------------------------\n",
        "categorical_columns = X_train_raw.select_dtypes(include='object').columns\n",
        "rare_threshold = 100  # Ελάχιστες εμφανίσεις για να κρατήσουμε την τιμή ως \"μη σπάνια\"\n",
        "\n",
        "for col in categorical_columns:\n",
        "    value_counts = X_train_raw[col].value_counts()\n",
        "    rare_values = value_counts[value_counts < rare_threshold].index\n",
        "\n",
        "    X_train_raw[col] = X_train_raw[col].replace(rare_values, 'rare')\n",
        "    X_test_raw[col]  = X_test_raw[col].replace(rare_values, 'rare')\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Label Encoding των στόχων (attack_cat)\n",
        "# ----------------------------------------------------------\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_int = label_encoder.fit_transform(df_train['attack_cat'])\n",
        "y_test_int  = label_encoder.transform(df_test['attack_cat'])\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"Κλάσεις ταξινόμησης: {label_encoder.classes_}\")\n",
        "\n",
        "# Αποθήκευση encoder για μελλοντική χρήση (π.χ. API)\n",
        "with open(\"attack_cat_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# One-Hot Encoding των κατηγορικών γνωρισμάτων\n",
        "# ----------------------------------------------------------\n",
        "X_train_ohe = pd.get_dummies(X_train_raw, columns=categorical_columns)\n",
        "X_test_ohe  = pd.get_dummies(X_test_raw,  columns=categorical_columns)\n",
        "\n",
        "# Ευθυγράμμιση κοινών χαρακτηριστικών μεταξύ train και test\n",
        "common_features = X_train_ohe.columns.intersection(X_test_ohe.columns)\n",
        "X_train_aligned = X_train_ohe[common_features]\n",
        "X_test_aligned  = X_test_ohe[common_features]\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Κανονικοποίηση γνωρισμάτων (MinMax Scaling)\n",
        "# ----------------------------------------------------------\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_aligned)\n",
        "X_test_scaled  = scaler.transform(X_test_aligned)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Train/Validation Split με stratify\n",
        "# ----------------------------------------------------------\n",
        "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
        "    X_train_scaled,\n",
        "    y_train_int,\n",
        "    test_size=0.2,\n",
        "    stratify=y_train_int,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αντιμετώπιση Imbalance με SMOTE στο training set\n",
        "# ----------------------------------------------------------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_final, y_train_final)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# One-Hot Encoding στα labels για MLP & CNN\n",
        "# ----------------------------------------------------------\n",
        "y_train_ohe = to_categorical(y_train_resampled, num_classes=num_classes)\n",
        "y_val_ohe   = to_categorical(y_val_final,     num_classes=num_classes)\n",
        "y_test_ohe  = to_categorical(y_test_int,      num_classes=num_classes)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Έλεγχος shapes\n",
        "# ----------------------------------------------------------\n",
        "print(f\"X_train shape: {X_train_resampled.shape}\")\n",
        "print(f\"X_val shape:   {X_val_final.shape}\")\n",
        "print(f\"X_test shape:  {X_test_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train_ohe.shape}\")\n",
        "print(f\"y_val shape:   {y_val_ohe.shape}\")\n",
        "print(f\"y_test shape:  {y_test_ohe.shape}\")\n"
      ],
      "metadata": {
        "id": "49Bo757bB2wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. MLP"
      ],
      "metadata": {
        "id": "Pi6tEsMoDVx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# MLP με 3 hidden layers + Keras Tuner\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('dense_units_1', 128, 512, step=64),\n",
        "        activation='relu',\n",
        "        input_shape=(X_train_resampled.shape[1],)\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout_1', 0.2, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('dense_units_2', 64, 256, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout_2', 0.2, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('dense_units_3', 32, 128, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout_3', 0.2, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    learning_rate = hp.Choice('learning_rate', [0.01, 0.001, 0.0001])\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# Default parameters από το tuner\n",
        "default_params = {\n",
        "    'dense_units_1': 256,\n",
        "    'dropout_1': 0.3,\n",
        "    'dense_units_2': 128,\n",
        "    'dropout_2': 0.3,\n",
        "    'dense_units_3': 64,\n",
        "    'dropout_3': 0.3,\n",
        "    'learning_rate': 0.001\n",
        "}\n",
        "\n",
        "\n",
        "def build_default_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(default_params['dense_units_1'], activation='relu',\n",
        "                    input_shape=(X_train_resampled.shape[1],)))\n",
        "    model.add(Dropout(default_params['dropout_1']))\n",
        "\n",
        "    model.add(Dense(default_params['dense_units_2'], activation='relu'))\n",
        "    model.add(Dropout(default_params['dropout_2']))\n",
        "\n",
        "    model.add(Dense(default_params['dense_units_3'], activation='relu'))\n",
        "    model.add(Dropout(default_params['dropout_3']))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=default_params['learning_rate']),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "\n",
        "if USE_TUNER:\n",
        "    tuner = kt.Hyperband(\n",
        "        build_model,\n",
        "        objective='val_accuracy',\n",
        "        max_epochs=50,\n",
        "        factor=3,\n",
        "        directory='kt_dir',\n",
        "        project_name='mlp_unsw_3hidden'\n",
        "    )\n",
        "\n",
        "    tuner.search(\n",
        "        X_train_resampled,\n",
        "        y_train_ohe,\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        validation_data=(X_val_final, y_val_ohe),\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "    print(f\"\"\"\n",
        "    ΒΕΛΤΙΣΤΕΣ ΥΠΕΡΠΑΡΑΜΕΤΡΟΙ:\n",
        "    - dense_units_1: {best_hps.get('dense_units_1')}\n",
        "    - dense_units_2: {best_hps.get('dense_units_2')}\n",
        "    - dense_units_3: {best_hps.get('dense_units_3')}\n",
        "    - dropout_1: {best_hps.get('dropout_1')}\n",
        "    - dropout_2: {best_hps.get('dropout_2')}\n",
        "    - dropout_3: {best_hps.get('dropout_3')}\n",
        "    - learning_rate: {best_hps.get('learning_rate')}\n",
        "    \"\"\")\n",
        "\n",
        "    tuner.results_summary()\n",
        "    best_model = tuner.hypermodel.build(best_hps)\n",
        "else:\n",
        "    print(\"Χρήση DEFAULT τιμών χωρίς Keras Tuner\")\n",
        "    best_model = build_default_model()\n",
        "\n",
        "\n",
        "# Εκπαίδευση του τελικού μοντέλου\n",
        "history = best_model.fit(\n",
        "    X_train_resampled,\n",
        "    y_train_ohe,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val_final, y_val_ohe),\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# Αξιολόγηση στο test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test_scaled, y_test_ohe)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Αποθήκευση τελικού μοντέλου\n",
        "best_model.save(\"best_mlp_unsw_3hidden.h5\")\n"
      ],
      "metadata": {
        "id": "0K1BFRRkDTpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Αξιολόγηση MLP"
      ],
      "metadata": {
        "id": "PNMiCA4VzD5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Διαγράμματα εκπαίδευσης\n",
        "# ---------------------------\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Loss ανά Εποχή\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Ακρίβεια ανά Εποχή\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------\n",
        "# Προβλέψεις στο test set\n",
        "# ---------------------------\n",
        "y_test_predictions_proba = best_model.predict(X_test_scaled)\n",
        "y_test_predictions = np.argmax(y_test_predictions_proba, axis=1)\n",
        "y_test_true = np.argmax(y_test_ohe, axis=1)\n",
        "\n",
        "# ---------------------------\n",
        "# Classification Report\n",
        "# ---------------------------\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    y_test_true,\n",
        "    y_test_predictions,\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "# ---------------------------\n",
        "# Confusion Matrix\n",
        "# ---------------------------\n",
        "conf_matrix = confusion_matrix(y_test_true, y_test_predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)\n",
        "disp.plot(xticks_rotation=90, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------\n",
        "# Επιπλέον Μετρικά\n",
        "# ---------------------------\n",
        "print(f\"\\nMacro F1 Score:      {f1_score(y_test_true, y_test_predictions, average='macro'):.4f}\")\n",
        "print(f\"Weighted F1 Score:   {f1_score(y_test_true, y_test_predictions, average='weighted'):.4f}\")\n",
        "print(f\"Micro F1 Score:      {f1_score(y_test_true, y_test_predictions, average='micro'):.4f}\")\n",
        "print(f\"Macro Precision:     {precision_score(y_test_true, y_test_predictions, average='macro'):.4f}\")\n",
        "print(f\"Macro Recall:        {recall_score(y_test_true, y_test_predictions, average='macro'):.4f}\")\n"
      ],
      "metadata": {
        "id": "4E9E0h_sDx3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "QUVfj4A_Gy2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Extra Preprocessing Βήμα για CNN\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# Reshape 3D: (samples, features, 1) για χρήση σε Conv1D\n",
        "X_train_cnn = X_train_resampled.reshape(-1, X_train_resampled.shape[1], 1)\n",
        "X_val_cnn   = X_val_final.reshape(-1, X_val_final.shape[1], 1)\n",
        "X_test_cnn  = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "tjNOGq-3G8gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Custom Model με τις Καλύτερες Τιμές (από tuner)\n",
        "# ----------------------------------------------------------\n",
        "def build_custom_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train_cnn.shape[1], 1)))\n",
        "\n",
        "    # Καλύτερες τιμές που έβγαλε ο tuner\n",
        "    filters = 256\n",
        "    kernel_size = 7\n",
        "    dropout_rate = 0.3\n",
        "    dense_units = 192\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # CNN Αρχιτεκτονική\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# CNN Model με Tuner\n",
        "# ----------------------------------------------------------\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train_cnn.shape[1], 1)))\n",
        "\n",
        "    # Υπερπαράμετροι\n",
        "    filters = hp.Int(\"filters\", min_value=64, max_value=256, step=64)\n",
        "    kernel_size = hp.Choice(\"kernel_size\", values=[3, 5, 7])\n",
        "    dropout_rate = hp.Float(\"dropout\", min_value=0.1, max_value=0.4, step=0.1)\n",
        "    dense_units = hp.Int(\"dense_units\", min_value=64, max_value=256, step=64)\n",
        "    learning_rate = hp.Float(\"lr\", min_value=0.0001, max_value=0.01, sampling=\"log\")\n",
        "\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Keras Tuner Setup\n",
        "# ----------------------------------------------------------\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=30,\n",
        "    executions_per_trial=1,\n",
        "    directory='kt_dir',\n",
        "    project_name='cnn_unsw'\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Εκπαίδευση\n",
        "# ----------------------------------------------------------\n",
        "if USE_TUNER:\n",
        "    tuner.search(\n",
        "        X_train_cnn, y_train_ohe,\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        validation_data=(X_val_cnn, y_val_ohe),\n",
        "        callbacks=[early_stop, reduce_lr]\n",
        "    )\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "else:\n",
        "    print(\"Χρήση custom CNN με default τιμές (χωρίς tuner)\")\n",
        "    model = build_custom_model()\n",
        "    history = model.fit(\n",
        "        X_train_cnn, y_train_ohe,\n",
        "        validation_data=(X_val_cnn, y_val_ohe),\n",
        "        epochs=50,\n",
        "        batch_size=128,\n",
        "        callbacks=[early_stop, reduce_lr]\n",
        "    )\n",
        "    best_model = model\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Περίληψη & Αξιολόγηση\n",
        "# ----------------------------------------------------------\n",
        "best_model.summary()\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test_cnn, y_test_ohe)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Αποθήκευση μοντέλου\n",
        "# ----------------------------------------------------------\n",
        "best_model.save(\"cnn_tabular_unsw_best.h5\")\n"
      ],
      "metadata": {
        "id": "4W3VSGaIHhe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Αξιολόγηση CNN"
      ],
      "metadata": {
        "id": "j5SClyIwzrp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# Διαγράμματα Εκπαίδευσης (Loss & Accuracy)\n",
        "# ----------------------------------------------------------\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Loss ανά Εποχή (CNN)\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Ακρίβεια ανά Εποχή (CNN)\")\n",
        "plt.xlabel(\"Εποχές\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Προβλέψεις στο test set\n",
        "# ----------------------------------------------------------\n",
        "y_test_pred_probs = best_model.predict(X_test_cnn)\n",
        "y_test_pred = np.argmax(y_test_pred_probs, axis=1)\n",
        "y_test_true = np.argmax(y_test_ohe, axis=1)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Classification Report\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\nClassification Report (CNN):\")\n",
        "print(classification_report(\n",
        "    y_test_true,\n",
        "    y_test_pred,\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Confusion Matrix\n",
        "# ----------------------------------------------------------\n",
        "conf_matrix = confusion_matrix(y_test_true, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)\n",
        "disp.plot(xticks_rotation=90, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (CNN)\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Επιπλέον Μετρικά\n",
        "# ----------------------------------------------------------\n",
        "print(f\"\\nMacro F1 Score:      {f1_score(y_test_true, y_test_pred, average='macro'):.4f}\")\n",
        "print(f\"Weighted F1 Score:   {f1_score(y_test_true, y_test_pred, average='weighted'):.4f}\")\n",
        "print(f\"Micro F1 Score:      {f1_score(y_test_true, y_test_pred, average='micro'):.4f}\")\n",
        "print(f\"Macro Precision:     {precision_score(y_test_true, y_test_pred, average='macro'):.4f}\")\n",
        "print(f\"Macro Recall:        {recall_score(y_test_true, y_test_pred, average='macro'):.4f}\")\n"
      ],
      "metadata": {
        "id": "hj9fUj-bLXY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}